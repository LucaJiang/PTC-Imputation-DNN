{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.2 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "6ad2903d9f8eb78095a8e1054d3b7d96029c25240c1559c5c7674409ebbac066"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import  utils\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn import manifold\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "from collections import namedtuple\n",
    "import os, re, time\n",
    "import random\n",
    "import shutil\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "\n",
    "# set seed to make sure the results are reproducible\n",
    "SEED = 123\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# change directory of data\n",
    "CV_ID = 1\n",
    "CV_ID = str(CV_ID)\n",
    "datapath = os.path.join(\".data\",\"hcb\",\"cv\" + CV_ID)\n",
    "save_name='basic-model-cv'+CV_ID+'.pt'\n",
    "train_dir = os.path.join(datapath, 'train')\n",
    "val_dir = os.path.join(datapath, 'val')\n",
    "test_dir = os.path.join(datapath, 'test')\n",
    "\n",
    "pretrained_size = (224, 224)\n",
    "pretrained_means = [0.485, 0.456, 0.406]\n",
    "pretrained_stds= [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "                           transforms.Resize(pretrained_size),\n",
    "                        #    transforms.RandomRotation(50),\n",
    "                           transforms.RandomRotation(30),\n",
    "                           transforms.RandomHorizontalFlip(0.4),\n",
    "                           transforms.RandomVerticalFlip(0.4),\n",
    "                           transforms.RandomCrop(pretrained_size, padding = 10),\n",
    "                           transforms.CenterCrop(pretrained_size),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean = pretrained_means, \n",
    "                                                std = pretrained_stds)\n",
    "                       ])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "                           transforms.Resize(pretrained_size),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean = pretrained_means, \n",
    "                                                std = pretrained_stds)\n",
    "                       ])\n",
    "# inorder to load img with it's label\n",
    "class MyImageFolder(datasets.ImageFolder):\n",
    "    def __getitem__(self, index):\n",
    "        path, _ = self.imgs[index] #img path, label\n",
    "        return super(MyImageFolder, self).__getitem__(index), path # return image path\n",
    "    \n",
    "\n",
    "BATCH_SIZE = 8#4\n",
    "train_data = MyImageFolder(root = train_dir,\n",
    "                                transform = train_transforms)\n",
    "test_data = MyImageFolder(root = test_dir,\n",
    "                                transform = test_transforms)\n",
    "valid_data = MyImageFolder(root = val_dir,\n",
    "                                transform = test_transforms)\n",
    "train_iterator = data.DataLoader(train_data, \n",
    "                                shuffle = True,\n",
    "                                drop_last = True,\n",
    "                                batch_size = BATCH_SIZE) \n",
    "valid_iterator = data.DataLoader(valid_data, drop_last = True,\n",
    "                                batch_size = BATCH_SIZE)\n",
    "test_iterator = data.DataLoader(test_data, drop_last = True,\n",
    "                                batch_size = BATCH_SIZE)     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-6\n",
    "EPOCHS = 400\n",
    "WEIGHT_DECAY=1e-3\n",
    "\n",
    "model = torch.hub.load('pytorch/vision:v0.6.0', 'resnet50')\n",
    "# change output dimension to what we need\n",
    "IN_FEATURES = model.fc.in_features \n",
    "OUTPUT_DIM = 2\n",
    "model.fc = nn.Linear(IN_FEATURES, OUTPUT_DIM)\n",
    "model.load_state_dict(torch.load('basic-model-hcb-pretrain.pt'))\n",
    "fc1=nn.Linear(IN_FEATURES, 32)\n",
    "fc2=nn.Linear(32,OUTPUT_DIM)\n",
    "model.fc = nn.Sequential(fc1, fc2)\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.tensor([1/256,1/410]).to(device))\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "params = [\n",
    "          {'params': model.conv1.parameters(), 'lr': LEARNING_RATE / 20},\n",
    "          {'params': model.bn1.parameters(), 'lr': LEARNING_RATE / 20},\n",
    "          {'params': model.layer1.parameters(), 'lr': LEARNING_RATE / 10},\n",
    "          {'params': model.layer2.parameters(), 'lr': LEARNING_RATE / 10},\n",
    "          {'params': model.layer3.parameters(), 'lr': LEARNING_RATE / 4},\n",
    "          {'params': model.layer4.parameters(), 'lr': LEARNING_RATE / 4},\n",
    "          {'params': model.fc.parameters(), 'lr': LEARNING_RATE}\n",
    "         ]\n",
    "optimizer = optim.Adam(params, lr = LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, 'min', factor=0.8, patience=5, min_lr=1e-30)\n",
    "\n",
    "# some functions for modelling\n",
    "def calculate_accuracy(y_pred, y):\n",
    "    with torch.no_grad():\n",
    "        batch_size = y.shape[0]\n",
    "        _, pred = torch.max(y_pred, 1)\n",
    "        correct = pred.eq(y).sum().item()\n",
    "        #correct = correct[:1].view(-1).float().sum(0, keepdim = True)\n",
    "        acc = correct / batch_size\n",
    "    return acc\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, scheduler, device):  \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.train()\n",
    "    for (xy, _id) in iterator:\n",
    "        x, y = xy\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        optimizer.zero_grad()      \n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred, y)\n",
    "        acc = calculate_accuracy(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # scheduler.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc\n",
    "        \n",
    "    epoch_loss /= len(iterator)\n",
    "    epoch_acc /= len(iterator)\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def evaluate(model, iterator, criterion, device):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for (xy, _id) in iterator:\n",
    "            x, y = xy\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            acc = calculate_accuracy(y_pred, y)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc\n",
    "        \n",
    "    epoch_loss /= len(iterator)\n",
    "    epoch_acc /= len(iterator)   \n",
    "    return epoch_loss, epoch_acc\n",
    "    \n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train the basic model\n",
    "print(BATCH_SIZE, LEARNING_RATE, WEIGHT_DECAY)\n",
    "best_valid_loss = float('inf')\n",
    "for epoch in range(EPOCHS):\n",
    "    start_time = time.time()\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, scheduler, device)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, device)\n",
    "    scheduler.step(valid_loss)     \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), save_name)\n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    print(f'Epoch: {epoch+1:02} / {EPOCHS} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Valid Loss: {valid_loss:.3f}|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(save_name))\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion, device)\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:6.2f}% ')"
   ]
  }
 ]
}